{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a83df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b03e6",
   "metadata": {},
   "source": [
    "## Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88852fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'When we were in Paris we visited a lot of museums. We first went to the Louvre, the largest art museum in the world. I have always been interested in art so I spent many hours there. The museum is enourmous, so a week there would not be enough.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fbe919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Detr1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986ddeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When we were in Paris we visited a lot of museums.',\n",
       " 'We first went to the Louvre, the largest art museum in the world.',\n",
       " 'I have always been interested in art so I spent many hours there.',\n",
       " 'The museum is enourmous, so a week there would not be enough.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cba1cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'we', 'were', 'in', 'Paris', 'we', 'visited', 'a', 'lot', 'of', 'museums', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9812132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'we', 'were', 'in', 'Paris', 'we', 'visited', 'a', 'lot', 'of', 'museums', '.', 'We', 'first', 'went', 'to', 'the', 'Louvre', ',', 'the', 'largest', 'art', 'museum', 'in', 'the', 'world', '.', 'I', 'have', 'always', 'been', 'interested', 'in', 'art', 'so', 'I', 'spent', 'many', 'hours', 'there', '.', 'The', 'museum', 'is', 'enourmous', ',', 'so', 'a', 'week', 'there', 'would', 'not', 'be', 'enough', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for sentence in sentences:\n",
    "    t = word_tokenize(sentence)\n",
    "    tokens.extend(t)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde37487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Detr1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e90ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris', 'visited', 'lot', 'museums', 'first', 'went', 'louvre', 'largest', 'art', 'museum', 'world', 'always', 'interested', 'art', 'spent', 'many', 'hours', 'museum', 'enourmous', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "unique_stops = set(stopwords.words('english'))\n",
    "no_stops = []\n",
    "for token in tokens:\n",
    "    token = token.lower()\n",
    "    if token not in unique_stops and token.isalpha():\n",
    "        no_stops.append(token)\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4d12931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Detr1\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7568935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris', 'visited', 'lot', 'museum', 'first', 'went', 'louvre', 'largest', 'art', 'museum', 'world', 'always', 'interested', 'art', 'spent', 'many', 'hour', 'museum', 'enourmous', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = []\n",
    "for token in no_stops:\n",
    "    token = lemmatizer.lemmatize(token)\n",
    "    lemmatized.append(token)\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a76ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pari', 'visit', 'lot', 'museum', 'first', 'went', 'louvr', 'largest', 'art', 'museum', 'world', 'alway', 'interest', 'art', 'spent', 'mani', 'hour', 'museum', 'enourm', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "stemmed_p = [porter.stem(s) for s in lemmatized]\n",
    "print(stemmed_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413fa370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['par', 'visit', 'lot', 'muse', 'first', 'went', 'louvr', 'largest', 'art', 'muse', 'world', 'alway', 'interest', 'art', 'spent', 'many', 'hour', 'muse', 'enourm', 'week', 'would', 'enough']\n"
     ]
    }
   ],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "stemmed_l = [lancaster.stem(s) for s in lemmatized]\n",
    "print(stemmed_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f24e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'museum': 3, 'art': 2, 'paris': 1, 'visited': 1, 'lot': 1, 'first': 1, 'went': 1, 'louvre': 1, 'largest': 1, 'world': 1, 'always': 1, 'interested': 1, 'spent': 1, 'many': 1, 'hour': 1, 'enourmous': 1, 'week': 1, 'would': 1, 'enough': 1})\n"
     ]
    }
   ],
   "source": [
    "bow_counter = Counter(lemmatized)\n",
    "print(bow_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32c89fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('museum', 3), ('art', 2), ('paris', 1), ('visited', 1), ('lot', 1), ('first', 1), ('went', 1), ('louvre', 1), ('largest', 1), ('world', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac5e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                            lowercase = True,\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = ['english'],\n",
    "                            max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3e870b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "bow_cv = vectorizer.fit_transform(sentences)\n",
    "print(type(bow_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d29074f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 2 0 0 1 1 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 3 0 1 0 1 0 1 0 0 1 0]\n",
      " [1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_cv.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08989962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 34)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56814796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'when': 31, 'we': 27, 'were': 30, 'in': 9, 'paris': 20, 'visited': 26, 'lot': 13, 'of': 19, 'museums': 17, 'first': 6, 'went': 29, 'to': 25, 'the': 23, 'louvre': 14, 'largest': 12, 'art': 1, 'museum': 16, 'world': 32, 'have': 7, 'always': 0, 'been': 3, 'interested': 10, 'so': 21, 'spent': 22, 'many': 15, 'hours': 8, 'there': 24, 'is': 11, 'enourmous': 5, 'week': 28, 'would': 33, 'not': 18, 'be': 2, 'enough': 4}\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "300adc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['always', 'art', 'be', 'been', 'enough', 'enourmous', 'first',\n",
       "       'have', 'hours', 'in', 'interested', 'is', 'largest', 'lot',\n",
       "       'louvre', 'many', 'museum', 'museums', 'not', 'of', 'paris', 'so',\n",
       "       'spent', 'the', 'there', 'to', 'visited', 'we', 'week', 'went',\n",
       "       'were', 'when', 'world', 'would'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = vectorizer.get_feature_names_out()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe3530af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>always</th>\n",
       "      <th>art</th>\n",
       "      <th>be</th>\n",
       "      <th>been</th>\n",
       "      <th>enough</th>\n",
       "      <th>enourmous</th>\n",
       "      <th>first</th>\n",
       "      <th>have</th>\n",
       "      <th>hours</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>there</th>\n",
       "      <th>to</th>\n",
       "      <th>visited</th>\n",
       "      <th>we</th>\n",
       "      <th>week</th>\n",
       "      <th>went</th>\n",
       "      <th>were</th>\n",
       "      <th>when</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            always  art  be  been  enough  enourmous  first  have  hours  in  \\\n",
       "Sentence_0       0    0   0     0       0          0      0     0      0   1   \n",
       "Sentence_1       0    1   0     0       0          0      1     0      0   1   \n",
       "Sentence_2       1    1   0     1       0          0      0     1      1   1   \n",
       "Sentence_3       0    0   1     0       1          1      0     0      0   0   \n",
       "\n",
       "            ...  there  to  visited  we  week  went  were  when  world  would  \n",
       "Sentence_0  ...      0   0        1   2     0     0     1     1      0      0  \n",
       "Sentence_1  ...      0   1        0   1     0     1     0     0      1      0  \n",
       "Sentence_2  ...      1   0        0   0     0     0     0     0      0      0  \n",
       "Sentence_3  ...      1   0        0   0     1     0     0     0      0      1  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = []\n",
    "for i, _ in enumerate(bow_cv):\n",
    "    index_list.append(f'Sentence_{i}')\n",
    "bow_cv_df = pd.DataFrame(data = bow_cv.toarray(),\n",
    "                        index = index_list,\n",
    "                        columns = tokens)\n",
    "bow_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17d35f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x34 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b17c5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "tfidf_trans.fit(bow_cv)\n",
    "df_idf = pd.DataFrame(tfidf_trans.idf_, index = tokens, columns = [\"idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d28c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x34 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector = tfidf_trans.transform(bow_cv)\n",
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3491d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0         1         2         3\n",
      "always      0.000000  0.000000  0.328404  0.000000\n",
      "art         0.000000  0.211724  0.258918  0.000000\n",
      "be          0.000000  0.000000  0.000000  0.324676\n",
      "been        0.000000  0.000000  0.328404  0.000000\n",
      "enough      0.000000  0.000000  0.000000  0.324676\n",
      "enourmous   0.000000  0.000000  0.000000  0.324676\n",
      "first       0.000000  0.268544  0.000000  0.000000\n",
      "have        0.000000  0.000000  0.328404  0.000000\n",
      "hours       0.000000  0.000000  0.328404  0.000000\n",
      "in          0.202925  0.171408  0.209616  0.000000\n",
      "interested  0.000000  0.000000  0.328404  0.000000\n",
      "is          0.000000  0.000000  0.000000  0.324676\n",
      "largest     0.000000  0.268544  0.000000  0.000000\n",
      "lot         0.317921  0.000000  0.000000  0.000000\n",
      "louvre      0.000000  0.268544  0.000000  0.000000\n",
      "many        0.000000  0.000000  0.328404  0.000000\n",
      "museum      0.000000  0.211724  0.000000  0.255978\n",
      "museums     0.317921  0.000000  0.000000  0.000000\n",
      "not         0.000000  0.000000  0.000000  0.324676\n",
      "of          0.317921  0.000000  0.000000  0.000000\n",
      "paris       0.317921  0.000000  0.000000  0.000000\n",
      "so          0.000000  0.000000  0.258918  0.255978\n",
      "spent       0.000000  0.000000  0.328404  0.000000\n",
      "the         0.000000  0.635171  0.000000  0.255978\n",
      "there       0.000000  0.000000  0.258918  0.255978\n",
      "to          0.000000  0.268544  0.000000  0.000000\n",
      "visited     0.317921  0.000000  0.000000  0.000000\n",
      "we          0.501305  0.211724  0.000000  0.000000\n",
      "week        0.000000  0.000000  0.000000  0.324676\n",
      "went        0.000000  0.268544  0.000000  0.000000\n",
      "were        0.317921  0.000000  0.000000  0.000000\n",
      "when        0.317921  0.000000  0.000000  0.000000\n",
      "world       0.000000  0.268544  0.000000  0.000000\n",
      "would       0.000000  0.000000  0.000000  0.324676\n"
     ]
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tf_idf_vector.toarray(), \n",
    "                        columns = vectorizer.get_feature_names_out())\n",
    "print(df_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26293da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99650dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "tfIdf = tfIdfVectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef4022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['art' 'enourmous' 'hours' 'interested' 'largest' 'lot' 'louvre' 'museum'\n",
      " 'museums' 'paris' 'spent' 'visited' 'week' 'went' 'world']\n"
     ]
    }
   ],
   "source": [
    "print(tfIdfVectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7238a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51082562, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.51082562, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdfVectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09e32cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d80f7bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3\n",
      "art         0.0  0.344315  0.414289  0.000000\n",
      "enourmous   0.0  0.000000  0.000000  0.617614\n",
      "hours       0.0  0.000000  0.525473  0.000000\n",
      "interested  0.0  0.000000  0.525473  0.000000\n",
      "largest     0.0  0.436719  0.000000  0.000000\n",
      "lot         0.5  0.000000  0.000000  0.000000\n",
      "louvre      0.0  0.436719  0.000000  0.000000\n",
      "museum      0.0  0.344315  0.000000  0.486934\n",
      "museums     0.5  0.000000  0.000000  0.000000\n",
      "paris       0.5  0.000000  0.000000  0.000000\n",
      "spent       0.0  0.000000  0.525473  0.000000\n",
      "visited     0.5  0.000000  0.000000  0.000000\n",
      "week        0.0  0.000000  0.000000  0.617614\n",
      "went        0.0  0.436719  0.000000  0.000000\n",
      "world       0.0  0.436719  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tfIdf.toarray(), \n",
    "                        columns = tfIdfVectorizer.get_feature_names_out())\n",
    "print(df_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e77b1615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18965081782108964, 0.15440359274390048, 0.13136818731601646, 0.13136818731601646, 0.10917982746877804, 0.125, 0.10917982746877804, 0.2078121960479979, 0.125, 0.125, 0.13136818731601646, 0.125, 0.15440359274390048, 0.10917982746877804, 0.10917982746877804]\n"
     ]
    }
   ],
   "source": [
    "mean_weights = np.asarray(tfIdf.mean(axis=0)).ravel().tolist()\n",
    "print(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8400b011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>museum</td>\n",
       "      <td>0.207812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art</td>\n",
       "      <td>0.189651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enourmous</td>\n",
       "      <td>0.154404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>week</td>\n",
       "      <td>0.154404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interested</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spent</td>\n",
       "      <td>0.131368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lot</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>museums</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paris</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  mean_weights\n",
       "0      museum      0.207812\n",
       "1         art      0.189651\n",
       "2   enourmous      0.154404\n",
       "3        week      0.154404\n",
       "4       hours      0.131368\n",
       "5  interested      0.131368\n",
       "6       spent      0.131368\n",
       "7         lot      0.125000\n",
       "8     museums      0.125000\n",
       "9       paris      0.125000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_weights_df = pd.DataFrame({'term': tfIdfVectorizer.get_feature_names_out(),\n",
    "                               'mean_weights': mean_weights})\n",
    "mean_weights_df.sort_values(by = 'mean_weights', ascending = False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f6579",
   "metadata": {},
   "source": [
    "## Косинусное расстояние между текстовыми векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8258b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'all the world’s a stage, and all the men and women merely players'\n",
    "text2 = 'you must be the change you wish to see in the world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e1d0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [text1, text2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ddaa27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.4261596  0.4261596  0.4261596  0.4261596  0.\n",
      "  0.4261596  0.30321606]\n",
      " [0.6316672  0.         0.         0.         0.         0.6316672\n",
      "  0.         0.44943642]]\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "X = tfIdfVectorizer.fit_transform(corpus)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc9c2c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change</th>\n",
       "      <th>men</th>\n",
       "      <th>merely</th>\n",
       "      <th>players</th>\n",
       "      <th>stage</th>\n",
       "      <th>wish</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vector1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.303216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vector2</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.449436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           change      men   merely  players    stage      wish    women  \\\n",
       "vector1  0.000000  0.42616  0.42616  0.42616  0.42616  0.000000  0.42616   \n",
       "vector2  0.631667  0.00000  0.00000  0.00000  0.00000  0.631667  0.00000   \n",
       "\n",
       "            world  \n",
       "vector1  0.303216  \n",
       "vector2  0.449436  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_df = pd.DataFrame(data = X.toarray(), index = ['vector1', 'vector2'],\n",
    "                         columns = tfIdfVectorizer.get_feature_names_out())\n",
    "vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9437bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = X.toarray()[0]\n",
    "vector2 = X.toarray()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "822df75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8901a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1Len = np.linalg.norm(vector1)\n",
    "vector2Len = np.linalg.norm(vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46a45fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = vector1Len * vector2Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37e2811d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13627634143908643"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine = numerator/denominator\n",
    "cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d77d1272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4340946173847484"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_radians = np.arccos(cosine)\n",
    "angle_radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fcd0fec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.17"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_degrees = angle_radians * 180/np.pi\n",
    "round(angle_degrees, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c3c54",
   "metadata": {},
   "source": [
    "## Кластерный анализ текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "676cf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.\n",
    "It applies knowledge and actionable insights from data across a broad range of application domains.\n",
    "Data science is related to data mining, machine learning and big data.\n",
    "The Bolshoi Theatre is a historic theatre in Moscow, Russia.\n",
    "It was originally designed by architect Joseph Bové, which holds ballet and opera performances.\n",
    "Before the October Revolution it was a part of the Imperial Theatres of the Russian Empire along with Maly Theatre in Moscow and a few theatres in Saint Petersburg.\n",
    "Data science is a concept to unify statistics, data analysis, informatics, and their related methods in order to understand and analyze actual phenomena with data.\n",
    "However, data science is different from computer science and information science.\n",
    "The main building of the theatre, rebuilt and renovated several times during its history, is a landmark of Moscow and Russia.\n",
    "On 28 October 2011, the Bolshoi re-opened after an extensive six-year renovation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a79aee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.',\n",
       " 'it applies knowledge and actionable insights from data across a broad range of application domains.',\n",
       " 'data science is related to data mining, machine learning and big data.',\n",
       " 'the bolshoi theatre is a historic theatre in moscow, russia.',\n",
       " 'it was originally designed by architect joseph bové, which holds ballet and opera performances.',\n",
       " 'before the october revolution it was a part of the imperial theatres of the russian empire along with maly theatre in moscow and a few theatres in saint petersburg.',\n",
       " 'data science is a concept to unify statistics, data analysis, informatics, and their related methods in order to understand and analyze actual phenomena with data.',\n",
       " 'however, data science is different from computer science and information science.',\n",
       " 'the main building of the theatre, rebuilt and renovated several times during its history, is a landmark of moscow and russia.',\n",
       " 'on 28 october 2011, the bolshoi re-opened after an extensive six-year renovation.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for line in text.split('\\n'):\n",
    "    if line:\n",
    "        line = line.lower()\n",
    "        corpus.append(line)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "675e447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True, stop_words='english')\n",
    "X = tfIdfVectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24d68345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Detr1\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc0ad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = ['Many statisticians, including Nate Silver, have argued that data science is not a new field, but rather another name for statistics.',\n",
    "              'Urusov set up the theatre in collaboration with English tightrope walker Michael Maddox.',\n",
    "              'Until the mid-1990s, most foreign operas were sung in Russian, but Italian and other languages have been heard more frequently on the Bolshoi stage in recent years.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b123d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_prediction = tfIdfVectorizer.transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6486b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x76 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "698028c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(tfidf_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
